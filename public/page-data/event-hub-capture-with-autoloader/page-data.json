{"componentChunkName":"component---src-components-post-layout-js","path":"/event-hub-capture-with-autoloader/","result":{"data":{"mdx":{"id":"938e389c-6f4d-5a42-a3cb-3a56ad034cea","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Stream Processing Event Hub Capture files with Autoloader\",\n  \"date\": \"2021-01-04T00:00:00.000Z\",\n  \"published\": true,\n  \"tags\": [\"Event Hub\", \"Databricks\", \"Spark\", \"Streaming\"],\n  \"description\": \"Processing avro files and payloads from Event Hub Capture with Databricks Autoloader\",\n  \"toc\": true,\n  \"seoImage\": \"og-event-hub-capture-with-autoloader.png\",\n  \"featuredImage\": \"./featured-image.png\"\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-capture-overview\"\n  }), \"Event Hub Capture\"), \" is a reliable, hassle-free and cost-effective way to easily ingest Event Hub data in a Data Lake, enabling a number of downstream use cases, such as:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Going beyond the 7 day retention period: \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-faq#what-is-the-maximum-retention-period-for-events\"\n  }), \"link\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Analytical exploration on historical data: a great article \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://medium.com/streaming-at-scale-in-azure/streaming-at-scale-with-event-hub-capture-79c30fb9f3e5\"\n  }), \"here\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"And the general flexibility that comes with having a managed event deserialization pipeline (without Event Hub Capture, we'd otherwise have to implement the pipeline from scratch)\")), mdx(\"p\", null, \"Once Capture is set up with a \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-capture-enable-through-portal#capture-data-to-azure-storage\"\n  }), \"couple clicks\"), \", captured data is written in \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" format with the semantics below:\\n\", mdx(\"figure\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1496px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"20.416666666666668%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABcRAAAXEQHKJvM/AAAA70lEQVQY0zWP7W6DMAxFeY61AwIp0IYQktDyVRjtKq2dJu39X8Z3Bmk/rGNZ1/FJsE8qEpmjMDUUZZZS3ZNsFkqYIvcUHyzFPP9nss6Y77wXFw1J/0HSzbzr6C0uKRC5g7nckFU91PkGN3/Df/6inl4w4xeUn6HsFaoeobm37R2lm5CeztDdA275geXK7YSd0Aj2bJbUEx3aB4lqoB1fTv1CsR4oPJ4pUh0Jto3YJlIthStPLcVrlR1nLlsmlDXxgxSkHPLzC830JMMXZdnBT09otpaqRaZ77u8o6ityM2ws2Dhn49yM/LNh42ofSoM/SAN7nB+CKKkAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Capture Semantics\",\n    \"title\": \"Capture Semantics\",\n    \"src\": \"/static/fda792ee6c0e504a4946dd9d4fcfae48/6ee55/capture-semantics.png\",\n    \"srcSet\": [\"/static/fda792ee6c0e504a4946dd9d4fcfae48/9aebd/capture-semantics.png 480w\", \"/static/fda792ee6c0e504a4946dd9d4fcfae48/a91f8/capture-semantics.png 960w\", \"/static/fda792ee6c0e504a4946dd9d4fcfae48/6ee55/capture-semantics.png 1496w\"],\n    \"sizes\": \"(max-width: 1496px) 100vw, 1496px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }), \"Capture Semantics\"), \"\\n  \")), mdx(\"p\", null, \"At this point, we have full creative freedom on how we want to process these \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" files.\"), mdx(\"p\", null, \"The most straightforward way would be for us to process the incoming data in batches and persist/UPSERT into a relational store (e.g. \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.databricks.com/delta/delta-update.html#upsert-into-a-table-using-merge\"\n  }), \"Delta Tables\"), \", \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/sql/t-sql/statements/merge-transact-sql?view=sql-server-ver15\"\n  }), \"Synapse SQL Pools\"), \"), similar to any average Batch Ingestion pipeline (couple articles here on batch ingesting Event Hub Capture files: \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://caiomsouza.medium.com/processing-event-hubs-capture-files-avro-format-using-spark-azure-databricks-save-to-parquet-95259001d85f\"\n  }), \"1\"), \", \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"http://blog.itaysk.com/2017/01/14/processing-event-hub-capture-files-using-spark\"\n  }), \"2\"), \", \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://simonlearningsqlserver.wordpress.com/category/databricks/\"\n  }), \"3\"), \").\"), mdx(Callout, {\n    mdxType: \"Callout\"\n  }, mdx(\"p\", null, \"\\uD83D\\uDCA8 To skip straight to the pipeline, click \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"#the-pipeline\"\n  }), \"here\"), \".\")), mdx(\"h2\", {\n    \"id\": \"why-autoloader\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#why-autoloader\",\n    \"aria-label\": \"why autoloader permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Why Autoloader?\"), mdx(\"p\", null, \"There are a couple fundamental disadvantages with the traditional approach:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"We miss out on creating an \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"a\", _extends({\n    parentName: \"strong\"\n  }, {\n    \"href\": \"https://talks.rmoff.net/nw3OuA/the-changing-face-of-etl-event-driven-architectures-for-data-engineers\"\n  }), \"Event-Driven\")), \" pipeline.\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Every time a new file is being dropped into our Storage Account, Azure's infrastructure captures an \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-event-overview\"\n  }), \"\\\"Event\\\"\"), \", and makes the event metadata (e.g. \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"what/when\"), \") available to us via an \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/event-grid/overview\"\n  }), \"Event Grid\"), \". We can choose to build downstream pipelines that \\\"react\\\" to these events (or queue them up and process them \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"as a stream\"), \" with \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://databricks.com/blog/2017/05/22/running-streaming-jobs-day-10x-cost-savings.html\"\n  }), mdx(\"code\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"Trigger.Once\")), \"), allowing for tighter, more efficient end-to-end integration (rather than processing on a timer based schedule).\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"When we process the capture data as a batch, we're essentially not taking advantages of these Events. As a result, say we schedule the Batch job every hour, there might be times when we process a large number of events (peak times), at other times, the job might run only to find there are no events to process at all.\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Using an Event-Driven pipeline allows us to minimize the backlog, and is a more efficient and elegant solution.\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Using the logic in the articles linked earlier showcases scanning the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"entire\"), \" set of captured \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" files into a DataFrame (fine for demo purposes), before we process it (UPSERT etc.), which can quickly become inefficient as the dataset grows in proportion to time.\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Of course, we can build in some sort of watermark/data-skipping logic into our pipeline (in addition to Spark's inherently \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"../spark-certification-study-guide-part-1/#dataframe-transformations-vs-actions-vs-operations\"\n  }), \"lazy\"), \" execution semantics, we can specifically tell it to only read in files from the capture folder \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"after\"), \" this time), but that requires us to design/implement/maintain that logic.\"), mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Using an Event-Driven pipeline lets us skip this altogether.\"))), mdx(\"p\", null, \"Databricks \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/databricks/spark/latest/structured-streaming/auto-loader\"\n  }), \"Autoloader\"), \" allows us to process incoming files by combining the main components driving an Event-Driven pipeline (configuring an Event Grid to listen to ADLS, setting up \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/storage/queues/storage-queues-introduction\"\n  }), \"queues\"), \" etc.) into an abstracted source called \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/databricks/spark/latest/structured-streaming/auto-loader#use-cloudfiles-source\"\n  }), mdx(\"code\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"cloudFiles\")), \".\"), mdx(\"p\", null, \"In this article, I wanted to share a sample design pattern on how we can apply Autoloader to process Event Hub Capture files.\"), mdx(Callout, {\n    mdxType: \"Callout\"\n  }, mdx(\"p\", null, \"\\uD83D\\uDCDD If you're not familiar with Autoloader, take a look at the illustrated view in \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"../braze-to-synapse-with-autoloader-illustrated/\"\n  }), \"this article\"), \".\")), mdx(\"h2\", {\n    \"id\": \"the-pipeline\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#the-pipeline\",\n    \"aria-label\": \"the pipeline permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"The Pipeline\"), mdx(Callout, {\n    mdxType: \"Callout\"\n  }, mdx(\"p\", null, \"\\uD83D\\uDCA1 I wrote this article in response to a \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/mdrakiburrahman/rakirahman.me/issues/2\"\n  }), \"request\"), \". If you have any interesting ideas for an article, feel free to open an issue on GitHub \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://github.com/mdrakiburrahman/rakirahman.me/issues/new\"\n  }), \"here\"), \"!\")), mdx(\"h3\", {\n    \"id\": \"producer\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"href\": \"#producer\",\n    \"aria-label\": \"producer permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Producer\"), mdx(\"p\", null, \"For our event producer, we have a simple Python script available in this \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-capture-python#create-a-python-script-to-send-events-to-your-event-hub\"\n  }), \"article\"), \", writing data into Event Hub as JSON payloads, where each event looks like this:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"json\"\n  }, mdx(\"pre\", _extends({\n    parentName: \"div\"\n  }, {\n    \"className\": \"language-json\"\n  }), mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-json\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"{\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token property\"\n  }), \"\\\"humidity\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \":\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token number\"\n  }), \"93\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token property\"\n  }), \"\\\"id\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \":\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"b4e4de2c-fb40-4313-8d6e-22f7d70ca75d\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token property\"\n  }), \"\\\"temperature\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \":\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token number\"\n  }), \"99\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token property\"\n  }), \"\\\"timestamp\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \":\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"2021-01-03 20:08:33.893592\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token property\"\n  }), \"\\\"uv\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \":\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token number\"\n  }), \"0.8591755189878726\"), \"\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"}\")))), mdx(\"p\", null, \"For this Event Hub, we can quickly enable Capture through the \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-capture-enable-through-portal#capture-data-to-azure-storage\"\n  }), \"Azure Portal\"), \".\"), mdx(\"p\", null, \"The key point to note here that will influence our design options going forward, is how we chose to serialize the payload. In this case, we went with \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"JSON\"), \", which as we'll shortly see, influences our options on how we can deserialize the payload downstream (i.e. in Spark).\"), mdx(Callout, {\n    mdxType: \"Callout\"\n  }, mdx(\"p\", null, \"\\uD83D\\uDCA1 Great article \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://www.confluent.io/blog/avro-kafka-data/\"\n  }), \"here\"), \" on why using \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" is a better idea for serializing payloads compared to \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"JSON\"), \".\")), mdx(\"h3\", {\n    \"id\": \"schema-parsing-capture-avro-and-payload-json\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"href\": \"#schema-parsing-capture-avro-and-payload-json\",\n    \"aria-label\": \"schema parsing capture avro and payload json permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Schema Parsing: capture (\", mdx(\"code\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \") and payload (\", mdx(\"code\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"json\"), \")\"), mdx(\"p\", null, \"Structured Streaming (which is the Spark API Autoloader \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/databricks/spark/latest/structured-streaming/auto-loader#use-cloudfiles-source\"\n  }), \"uses\"), \"), requires us to explicitly specify the schema via \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \".schema(<schema definition>)\"), \" when we declare the DataFrame. Spark documentation \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#schema-inference-and-partition-of-streaming-dataframesdatasets\"\n  }), \"here\"), \" describes this further.\"), mdx(\"p\", null, \"Event Hub Capture stores our payload in \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" format, with the following schema:\"), mdx(\"p\", null, mdx(\"figure\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1917px\"\n    }\n  }), \"\\n      \", mdx(\"a\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/2739b81e40c7a2d253cdc5a15ccff81c/f6862/schemas-to-parse.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"37.708333333333336%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABcRAAAXEQHKJvM/AAABz0lEQVQoz4WR227TQBCG/RA0xOtz4pzsnGzXzpkoIYQ0qHGLRBsSGlraJkXQAgXeEOWGd0C+4iXY1c86oChccfHp339mNDOaFaR09buc9b5JWW+dNJ01MUr/Ry+uxR3IDoLSPER+MIfZfg4STEBMD6Kch6hYIEoBRI3V4v7vmyNrNhS9uCX2klaEZJQhJGpjSP3pL71+RB+UhpQ4PWrWB9SsDWjK71PV7VLD79F08JhqXpeqPJZ59Ixm2gdcxzTbGW+8YtepqFpUSLhPsReETOMbis4B5OEU3vU93PM7OBcfUJi9RXB1j+bqK0pn72At3qPy5hMqr29R4TUb5XmjNYIo5bBpmPBDRuohtNoEcv8E1uwG9nSJ8vwGFlf//Bb+xR1K3Mex5uVHdFZf0F5+RpsPb3A1GsM/DffKT5AIQqo1j1myOmKkGbL85BXLHc6YfbxgucmcOSeXzDu9YtbRgnPGgtmKBS+vmc+pzZbM5V73e4zfngkPq6N4Q4iNEKnOCyhWA2qxhVS5Bc2sgv8qpFR5S+xTORdGtYuc20XG8rdxopcgJDP7P8VC40cy60fJbBDp+f1IyTiRnK5Ekl6MiGb/i25H/PiRxPPKbk2snN8kYvlywsdTHgAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Schemas to parse\",\n    \"title\": \"Schemas to parse\",\n    \"src\": \"/static/2739b81e40c7a2d253cdc5a15ccff81c/f6862/schemas-to-parse.png\",\n    \"srcSet\": [\"/static/2739b81e40c7a2d253cdc5a15ccff81c/9aebd/schemas-to-parse.png 480w\", \"/static/2739b81e40c7a2d253cdc5a15ccff81c/a91f8/schemas-to-parse.png 960w\", \"/static/2739b81e40c7a2d253cdc5a15ccff81c/f6862/schemas-to-parse.png 1917w\"],\n    \"sizes\": \"(max-width: 1917px) 100vw, 1917px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }), \"Schemas to parse\"), \"\\n  \")), mdx(\"p\", null, \"There's \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"2\"), \" places here where we need to supply Spark with the schema:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Capture Schema\"), \": i.e. the schema of the \", mdx(\"code\", _extends({\n    parentName: \"li\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" file from Event Hub capture. This schema is not likely to change very often - since it's managed by Azure and same for everyone (i.e. it's agnostic to our payload).\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"strong\", {\n    parentName: \"li\"\n  }, \"Payload Schema\"), \": i.e. the schema of our payload from the \", mdx(\"code\", _extends({\n    parentName: \"li\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"Body\"), \" column - which for this example is \", mdx(\"code\", _extends({\n    parentName: \"li\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"json\"), \". This schema is tied to our application logic.\")), mdx(\"p\", null, \"At this point, there are \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"3\"), \" methods we can leverage to supply Spark with the schemas above:\"), mdx(\"h4\", null, \"Method 1: \", mdx(\"code\", _extends({\n    parentName: \"h4\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"Sample payload file\")), mdx(\"p\", null, \"We can supply Spark with \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"sample files\"), \" (one for each of our schemas above), and have Spark infer the schema from these sample files before it kicks off the Autoloader pipeline.\"), mdx(\"p\", null, mdx(\"figure\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1711px\"\n    }\n  }), \"\\n      \", mdx(\"a\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/8c1b637aed245d7c50cea46d4eb2bb10/a66f5/passing-schema.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"28.125%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABcRAAAXEQHKJvM/AAABUUlEQVQY032MS0sCURiG5x8URWIKGl2glDKK0KBF7SyC7GJKVnhJIbxggVTSb2pTUEG0atEfaCXtbMbSmTOljg7B93ZmFIkWHXh43vfl4wjDUz4adkxTPJWjVKZAwajhM8qdFil7ckHZv+6S+U3+nPKFSwpGjkjwHKaxMDcL8V1Go9mGWP2CojZ41jgt1OvcDcPNnlstHW39u0dT02G8+8cnCKt+LyUPfFR6LZPKGMm1GjGFkSJzFKMrJmbvwpjaQ2WfJPNNb+t0fftAgsU+Bbt7iZ5fSpDeyiiLIhTGIEoVfFSrqNZq+OAwVYVUqfBdgqwopqXKu3lv3GiahqubOwi2ETec8yu0flzEfiKNnUgSm+E4NkJRBEIxMxsEwjHeo529m82+2/H2XgLL/i3+odMFm8tHdu8aJmcW4RjzYMA6jn7LaIehLpb/6eM3g9YJ/ACYcENxyboeWAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Sample files for Schema\",\n    \"title\": \"Sample files for Schema\",\n    \"src\": \"/static/8c1b637aed245d7c50cea46d4eb2bb10/a66f5/passing-schema.png\",\n    \"srcSet\": [\"/static/8c1b637aed245d7c50cea46d4eb2bb10/9aebd/passing-schema.png 480w\", \"/static/8c1b637aed245d7c50cea46d4eb2bb10/a91f8/passing-schema.png 960w\", \"/static/8c1b637aed245d7c50cea46d4eb2bb10/a66f5/passing-schema.png 1711w\"],\n    \"sizes\": \"(max-width: 1711px) 100vw, 1711px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }), \"Sample files for Schema\"), \"\\n  \")), mdx(\"p\", null, \"Note that in case of \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"JSON\"), \", Spark expects the data to be delimited per line (similar to \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://jsonlines.org/\"\n  }), \"JSONL\"), \"):\\n\", mdx(\"figure\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1284px\"\n    }\n  }), \"\\n      \", mdx(\"span\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"8.541666666666666%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAiElEQVQI1yWLSw6CQBBEuQUjCbpwZJCorVGWDp9piGGjUYGFGr3/JcrOsHipTtXrIO8GUPPEIneIj4z5qfVEBwe1r6GowIzOCLcF1M4KclMlfTWlOCGVfo+EIHU3aPtAwiOy7of15esx7QepZMIDMr5iWfYw9R1G/FXz9rvml3e0/GrbY2NH/AFPbkJuN9080AAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"{topic}-payload-sample.avro\",\n    \"title\": \"{topic}-payload-sample.avro\",\n    \"src\": \"/static/be225b88357fe58a5ff3170459b1a361/7b3ec/sample-payload.png\",\n    \"srcSet\": [\"/static/be225b88357fe58a5ff3170459b1a361/9aebd/sample-payload.png 480w\", \"/static/be225b88357fe58a5ff3170459b1a361/a91f8/sample-payload.png 960w\", \"/static/be225b88357fe58a5ff3170459b1a361/7b3ec/sample-payload.png 1284w\"],\n    \"sizes\": \"(max-width: 1284px) 100vw, 1284px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }), \"{topic}-payload-sample.avro\"), \"\\n  \")), mdx(\"p\", null, \"For Event Hub capture, we can simply copy any of the \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" files generated by Capture into \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"{topic}-sample.avro\"), \".\"), mdx(\"p\", null, \"Then, we can read in these sample files and construct the schema at runtime:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", _extends({\n    parentName: \"div\"\n  }, {\n    \"className\": \"language-python\"\n  }), mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# 1. Capture schema\"), \"\\ncapture_tmp \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" spark\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"read\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token builtin\"\n  }), \"format\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"avro\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"load\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"/mnt/bronze/tmp/{}-sample.avro\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token builtin\"\n  }), \"format\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"topic\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\ncapture_schema \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" capture_tmp\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"schema\\n\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# 2. Payload schema\"), \"\\npayload_tmp \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" spark\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"read\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"json\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"/mnt/bronze/tmp/{}-payload-sample.json\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token builtin\"\n  }), \"format\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"topic\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\npayload_schema \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" payload_tmp\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"schema\\n\"))), mdx(\"p\", null, \"If the payload schema changes, we need to simply upload a new file into the same location. For this demo, since our payload is in \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"JSON\"), \" (not supported by Azure Schema Registry yet), this is the method we'll be using.\"), mdx(Callout, {\n    mdxType: \"Callout\"\n  }, mdx(\"p\", null, \"\\u2B50 If we were using an \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" payload, \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Method 3\"), \" would hands down be the most elegant path forward.\")), mdx(\"p\", null, \"Although this isn't as elegant as using a Schema Registry (\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Method 3\"), \"), it still saves us the pain of defining the Schema structure by hand (\", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"Method 2\"), \").\"), mdx(\"h4\", null, \"Method 2: \", mdx(\"code\", _extends({\n    parentName: \"h4\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"Define schema in code\")), mdx(\"p\", null, \"Without using sample files, we can define the schema ourselves in code via \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"StructType\"), \": \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://sparkbyexamples.com/spark/spark-sql-structtype-on-dataframe/\"\n  }), \"example\"), \", and then by doing something like this:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", _extends({\n    parentName: \"div\"\n  }, {\n    \"className\": \"language-python\"\n  }), mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# ...\"), \"\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# Read in Avro Data from Capture with the same methods of defining the schema as below, into `autoloader_df`\"), \"\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# ...\"), \"\\n\\npayload_schema \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" StructType\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"[\"), \"\\n                StructField\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"humidity\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" LongType\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token boolean\"\n  }), \"True\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \"\\n                \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# ... Other columns\"), \"\\n                \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"]\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n\\npayload_df \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" autoloader_df \\\\\\n            \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"select\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"from_json\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"col\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"Body\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" defined_schema\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"alias\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"json_payload\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \" \\\\\\n            \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"select\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"json_payload.*\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \" \\\\\\n            \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# ... Perform other operations\")))), mdx(\"p\", null, \"The \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"benefit\"), \" here is, we don't have to worry about managing the sample payload file.\"), mdx(\"p\", null, \"The \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"disadvantage\"), \" is, the bits of code above for our \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"StructType\"), \" definition becomes the source of truth for the schema, which is not very dynamic - i.e. if the schema changes, we have to go into the code and update it. Also, if the schema is particularly complex (nested fields etc.), we need to write it all out ourselves.\"), mdx(\"h4\", null, \"Method 3: \", mdx(\"code\", _extends({\n    parentName: \"h4\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"Use Azure Schema Registry\")), mdx(\"p\", null, \"The most robust implementation would be to use Azure Schema Registry - illustrated \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"../azure-schemaregistry-spark/\"\n  }), \"here\"), \".\"), mdx(\"p\", null, \"However it's not immediately relevant for this particular use case since our \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"Body\"), \" is in \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"JSON\"), \" (at the time of writing, Azure Schema Registry currently only supports \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" payloads for now - \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://docs.microsoft.com/en-us/azure/event-hubs/schema-registry-overview#schemas\"\n  }), \"link\"), \").\"), mdx(\"h3\", {\n    \"id\": \"consumer-autoloader-with-method-1-for-schema-parsing\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h3\"\n  }, {\n    \"href\": \"#consumer-autoloader-with-method-1-for-schema-parsing\",\n    \"aria-label\": \"consumer autoloader with method 1 for schema parsing permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Consumer: Autoloader with Method 1 for Schema Parsing\"), mdx(Callout, {\n    mdxType: \"Callout\"\n  }, mdx(\"p\", null, \"\\uD83D\\uDCA1 We gloss over the Autoloader setup details below. Article explaining technical details on setting up Autoloader from scratch \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"../braze-to-synapse-with-autoloader\"\n  }), \"here\"), \".\")), mdx(\"p\", null, \"Now that we've dealt with the Capture Schema and Payload Schema, the Autoloader pipeline is no different than any other implementation.\"), mdx(\"p\", null, \"We pass in \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"capture_schema\"), \" first to read in the capture dataframe \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"autoloader_df\"), \":\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", _extends({\n    parentName: \"div\"\n  }, {\n    \"className\": \"language-python\"\n  }), mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"autoloader_df \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"spark\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"readStream\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token builtin\"\n  }), \"format\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"cloudFiles\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n                 \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"options\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"**\"), \"cloudFilesConf\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n                 \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"option\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"recursiveFileLookup\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"true\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# This lets us ignore folder level partitioning into the incoming Dataframe\"), \"\\n                 \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"schema\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"capture_schema\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# Event Hub Capture schema inferred from avro\"), \"\\n                 \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"load\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"wasbs://{}@{}.blob.core.windows.net/{}/{}/\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token builtin\"\n  }), \"format\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"capture_container\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" adls_account\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" eh_namespace\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" topic\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n                \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token comment\"\n  }), \"# Convert Body from Binary to String\"), \"\\nautoloader_df \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" autoloader_df\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"withColumn\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"Body\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" autoloader_df\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"[\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"Body\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"]\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"cast\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"StringType\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\")))), mdx(\"p\", null, mdx(\"figure\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1157px\"\n    }\n  }), \"\\n      \", mdx(\"a\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/46858752f383e8a43cf25f535907db9d/03e15/autoloader_df.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"40.625%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA3klEQVQoz42S2QqEMAxF+///KaLWra37kpkTiYwPAwYOKTFN7i26sqwkhChd10nf9zJNk8zzpHkcx1cMw6D3QwjicgbGpMWU0t20LIsQ53nevAnnGy8xRVXHQGB4jPGrdNYzoHhdV9m27bHkOI47g2uaRi+aOs7koiiEb7YAqHvvpaoqhTNCsAr0OIpMJvZ9V1BhC8wqdaJtW8nzXGEoTswZLnSg2cAS8H72yAxiIXVyXdeSZZmCC+t7KMQmQ+wy2Wqm0FygAlWAg+uvuHpZ6tiCXFNgtv9hj2/8fsPpB139bjJlmtFpAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Event Hub Capture after parsing\",\n    \"title\": \"Event Hub Capture after parsing\",\n    \"src\": \"/static/46858752f383e8a43cf25f535907db9d/03e15/autoloader_df.png\",\n    \"srcSet\": [\"/static/46858752f383e8a43cf25f535907db9d/9aebd/autoloader_df.png 480w\", \"/static/46858752f383e8a43cf25f535907db9d/a91f8/autoloader_df.png 960w\", \"/static/46858752f383e8a43cf25f535907db9d/03e15/autoloader_df.png 1157w\"],\n    \"sizes\": \"(max-width: 1157px) 100vw, 1157px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }), \"Event Hub Capture after parsing\"), \"\\n  \")), mdx(\"p\", null, \"Then, to get our original payload back, we pass in \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"payload_schema\"), \" and use \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"from_json\"), \":\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", _extends({\n    parentName: \"div\"\n  }, {\n    \"className\": \"language-python\"\n  }), mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), \"payload_df \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), \" autoloader_df \\\\\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"select\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"from_json\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"col\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"Body\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" payload_schema\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"alias\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"json_payload\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \" \\\\\\n              \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"select\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"json_payload.*\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\")))), mdx(\"p\", null, \"Note how we're able to get back our original payload, without manually defining the schema in code - thanks to the sample file:\"), mdx(\"p\", null, mdx(\"figure\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"gatsby-resp-image-figure\",\n    \"style\": {}\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"1153px\"\n    }\n  }), \"\\n      \", mdx(\"a\", _extends({\n    parentName: \"span\"\n  }, {\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/978bb2b57c2f07a418b1b19618d9aa7f/06fb1/payload_df.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }), \"\\n    \", mdx(\"span\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"40%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA5UlEQVQoz42R2w6DIBBE/f//VAN4FxUV3fasxTRtH0oyYcMsM8OSGWNlGAZp21bGcZQQFlmWC/M8/4VpmqTrOtXJCgRHL5P34p9IDSEEYZ3nqfh3Za52msw/RUmFUMK6riqOCRzCMUY5jkPrtL8jq6rqTkZd17U458Rae4+h73spy1L5pmluHtMvQWONEjgbY/QiyPNcZ0ITZhjBY8JeFMXPsWTJad93daWZBIiSjnOeTTr4JAz/MyGXmU+al399Dti2TTBGNH0WvXCkZ4Zfn8LTmBGCPJvLMe53jeh1Ft/4q4b7xAOxa2x7Twdj8wAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  })), \"\\n  \", mdx(\"img\", _extends({\n    parentName: \"a\"\n  }, {\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Payload after parsing\",\n    \"title\": \"Payload after parsing\",\n    \"src\": \"/static/978bb2b57c2f07a418b1b19618d9aa7f/06fb1/payload_df.png\",\n    \"srcSet\": [\"/static/978bb2b57c2f07a418b1b19618d9aa7f/9aebd/payload_df.png 480w\", \"/static/978bb2b57c2f07a418b1b19618d9aa7f/a91f8/payload_df.png 960w\", \"/static/978bb2b57c2f07a418b1b19618d9aa7f/06fb1/payload_df.png 1153w\"],\n    \"sizes\": \"(max-width: 1153px) 100vw, 1153px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  })), \"\\n  \"), \"\\n    \"), \"\\n    \", mdx(\"figcaption\", _extends({\n    parentName: \"figure\"\n  }, {\n    \"className\": \"gatsby-resp-image-figcaption\"\n  }), \"Payload after parsing\"), \"\\n  \")), mdx(\"p\", null, \"We now have our Event Hub Capture being parsed by the Autoloader pipeline, available in \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"payload_df\"), \".\"), mdx(\"p\", null, \"At this point, we're free to do whatever we want, such as writing to Delta Tables:\"), mdx(\"div\", {\n    \"className\": \"gatsby-highlight\",\n    \"data-language\": \"python\"\n  }, mdx(\"pre\", _extends({\n    parentName: \"div\"\n  }, {\n    \"className\": \"language-python\"\n  }), mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-python\"\n  }), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"payload_df\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"writeStream\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token builtin\"\n  }), \"format\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"delta\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"trigger\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), \"once\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token operator\"\n  }), \"=\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token boolean\"\n  }), \"True\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"outputMode\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"append\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"option\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"checkpointLocation\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \",\"), \" \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"your-checkpoint-location\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n  \", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \".\"), \"start\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \"(\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token string\"\n  }), \"\\\"your-delta-table-path\\\"\"), mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\"), \"\\n\", mdx(\"span\", _extends({\n    parentName: \"code\"\n  }, {\n    \"className\": \"token punctuation\"\n  }), \")\")))), mdx(\"h2\", {\n    \"id\": \"wrap-up\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#wrap-up\",\n    \"aria-label\": \"wrap up permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Wrap Up\"), mdx(\"p\", null, \"We explored how to use Autoloader to process Event Hub Capture files in an Event-Driven manner.\"), mdx(\"p\", null, \"The main takeaway here was figuring out how to deal with schema parsing for both the Capture \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" files and our Payload (\", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"json\"), \" for today) - we passed sample files over to Spark to infer the schema before kicking off Autoloader, but also discussed why using Azure Schema Registry would further strengthen the pipeline, had we used \", mdx(\"code\", _extends({\n    parentName: \"p\"\n  }, {\n    \"className\": \"language-text\"\n  }), \"avro\"), \" payloads.\"), mdx(Callout, {\n    mdxType: \"Callout\"\n  }, mdx(\"p\", null, \"\\uD83D\\uDCE6 Full consumer script available in GitHub \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://gist.github.com/mdrakiburrahman/5a0bc0c55eebe5173ed54a8db5e394c4\"\n  }), \"here\"), \".\")));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Stream Processing Event Hub Capture files with Autoloader","date":"January 4th 2021","datetime":"2021-01-04T00:00:00.000Z","description":"Processing avro files and payloads from Event Hub Capture with Databricks Autoloader","toc":true},"fields":{"slug":"/event-hub-capture-with-autoloader/"},"excerpt":"Event Hub Capture  is a reliable, hassle-free and cost-effective way to easily ingest Event Hub data in a Data Lake, enabling a number of","tableOfContents":{"items":[{"url":"#why-autoloader","title":"Why Autoloader?"},{"url":"#the-pipeline","title":"The Pipeline","items":[{"url":"#producer","title":"Producer"},{"url":"#schema-parsing-capture-avro-and-payload-json","title":"Schema Parsing: capture (avro) and payload (json)","items":[{"url":"#method-1-sample-payload-file","title":"Method 1: Sample payload file"},{"url":"#method-2-define-schema-in-code","title":"Method 2: Define schema in code"},{"url":"#method-3-use-azure-schema-registry","title":"Method 3: Use Azure Schema Registry"}]},{"url":"#consumer-autoloader-with-method-1-for-schema-parsing","title":"Consumer: Autoloader with Method 1 for Schema Parsing"}]},{"url":"#wrap-up","title":"Wrap Up"}]},"timeToRead":5},"ogImage":{"childImageSharp":{"fixed":{"src":"/static/6521922ca0303dca62d09cccef355dc6/e4d72/og-event-hub-capture-with-autoloader.png"}}}},"pageContext":{"id":"938e389c-6f4d-5a42-a3cb-3a56ad034cea","ogImageSlug":"og-event-hub-capture-with-autoloader.png"}}}